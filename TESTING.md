# Estrategia de Pruebas Completas - E-commerce Microservices

## ðŸ“‹ Resumen Ejecutivo

Este documento describe la estrategia integral de pruebas implementada para el proyecto de e-commerce basado en microservicios, adoptando un enfoque **Shift-Left** y principios de **FinOps** para optimizar recursos tÃ©cnicos y econÃ³micos en un entorno de infraestructura limitada (Azure Student Tier).

---

## ðŸ”º 1. PirÃ¡mide de Pruebas

La estrategia de testing sigue la pirÃ¡mide de pruebas de Mike Cohn, optimizada para desarrollo local con recursos limitados (8GB RAM).

```
       /\
      /  \     E2E (Ligero)
     /____\    MockMvc + TestRestTemplate
    /      \   
   /________\  IntegraciÃ³n
  /          \ H2 In-Memory + @SpringBootTest
 /____________\
/   Unitarias  \
 JUnit 5 + Mockito
```

### 1.1 Pruebas Unitarias (Base de la PirÃ¡mide)

**Framework:** JUnit 5 + Mockito + AssertJ

**Cobertura:** 
- Servicios (`@Service`)
- Recursos REST (`@RestController`)
- LÃ³gica de negocio aislada

**Beneficios:**
- âœ… EjecuciÃ³n rÃ¡pida (<5ms por test)
- âœ… Bajo consumo de memoria (~50MB por suite)
- âœ… Feedback inmediato en desarrollo local
- âœ… Alta cobertura de cÃ³digo (>20% actual, objetivo 30%)

**Ejemplo:**
```java
@Test
void testFindAllOrders_Unit() {
    // Given
    List<Order> mockOrders = Arrays.asList(
        Order.builder().orderId(1).orderDesc("Test Order").build()
    );
    when(orderRepository.findAll()).thenReturn(mockOrders);
    
    // When
    List<OrderDto> result = orderService.findAll();
    
    // Then
    assertThat(result).hasSize(1);
}
```

### 1.2 Pruebas de IntegraciÃ³n (Nivel Medio)

**Framework:** Spring Boot Test + H2 Database + TestRestTemplate

**ConfiguraciÃ³n:**
- Base de datos H2 en memoria (`MODE=MySQL`)
- Flyway deshabilitado en perfil `test`
- Spring Cloud Config deshabilitado
- Puerto aleatorio (`webEnvironment = RANDOM_PORT`)

**Ventajas:**
- âœ… Valida contratos REST reales
- âœ… Prueba serializaciÃ³n/deserializaciÃ³n JSON
- âœ… Bajo consumo de recursos (sin Docker/MySQL)
- âœ… Isolation entre tests (`@DirtiesContext`)

**ConfiguraciÃ³n (`application.yml` de pruebas):**
```yaml
spring:
  datasource:
    url: jdbc:h2:mem:testdb;MODE=MySQL
  jpa:
    hibernate:
      ddl-auto: create-drop
  flyway:
    enabled: false
  cloud:
    config:
      enabled: false
```

### 1.3 Pruebas E2E Ligeras (Cima de la PirÃ¡mide)

**Framework:** MockMvc + TestRestTemplate

**Estrategia:**
- Tests de flujo completo dentro del mismo contexto Spring
- Sin levantar Docker Compose completo (ahorro de ~2GB RAM)
- ValidaciÃ³n de endpoints HTTP sin infraestructura externa

**Limitaciones Aceptadas:**
- âŒ No prueba Eureka Discovery real
- âŒ No prueba API Gateway routing
- âŒ Foreign Key constraints en H2 (aceptable en test)

**JustificaciÃ³n FinOps:**
En lugar de levantar 10 contenedores Docker (Eureka, Config Server, Gateway, MySQL, Zipkin, etc.) consumiendo ~4GB RAM, se opta por pruebas E2E "ligeras" que validan los contratos REST y la lÃ³gica de negocio sin la sobrecarga de infraestructura completa.

---

## âš¡ 2. Estrategia de Performance: Smoke Test Distribuido

### 2.1 DecisiÃ³n ArquitectÃ³nica: Â¿Por quÃ© NO Stress Testing?

**Contexto:**
- Infraestructura: Azure Student Tier (recursos limitados)
- Presupuesto: CrÃ©dito estudiantil limitado ($100 USD/aÃ±o)
- Riesgo: Stress Testing agresivo puede saturar CPU y causar downtime

**DecisiÃ³n:**
Se adoptÃ³ un **Smoke Test Distribuido** en lugar de Stress Testing masivo, siguiendo principios de **FinOps** (Financial Operations).

### 2.2 ImplementaciÃ³n con Locust

**Herramienta:** Locust (Python-based load testing)

**ConfiguraciÃ³n Safe Mode:**
```python
class WebsiteUser(HttpUser):
    wait_time = between(1, 3)  # Espera 1-3s entre peticiones
    
    @task(3)
    def view_products(self):
        self.client.get("/product-service/api/products", verify=False)
    
    @task(1)
    def health_check(self):
        self.client.get("/product-service/actuator/health", verify=False)
```

**ParÃ¡metros de EjecuciÃ³n:**
- **Usuarios:** 20 usuarios concurrentes (no 500+)
- **Spawn Rate:** 1 usuario/segundo (crecimiento gradual)
- **DuraciÃ³n:** 2 minutos (suficiente para detectar issues)
- **Wait Time:** 1-3 segundos entre peticiones

**JustificaciÃ³n FinOps:**
| MÃ©trica | Stress Testing | Smoke Test (Nuestra Estrategia) |
|---------|---------------|----------------------------------|
| Usuarios concurrentes | 500-1000 | 20 |
| DuraciÃ³n | 10-30 min | 2 min |
| CPU Spike | >90% (riesgo throttling) | <50% |
| Costo estimado | ~$5-10/ejecuciÃ³n | <$0.10/ejecuciÃ³n |
| Riesgo de downtime | Alto | Bajo |

### 2.3 Objetivos del Smoke Test

âœ… **Validar disponibilidad:** Endpoints responden HTTP 200  
âœ… **Detectar memory leaks:** Monitorear uso de memoria durante 2 minutos  
âœ… **Medir latencia base:** P50, P95, P99 bajo carga moderada  
âœ… **Verificar health checks:** Actuator endpoints funcionan correctamente  

**No es objetivo:**
âŒ Encontrar el punto de quiebre del sistema  
âŒ Saturar todos los recursos disponibles  
âŒ Simular Black Friday (10,000+ usuarios)  

---

## ðŸ”’ 3. Seguridad: DAST con OWASP ZAP

### 3.1 Escaneo DinÃ¡mico de Seguridad

**Herramienta:** OWASP ZAP (Zed Attack Proxy)

**ConfiguraciÃ³n:**
- **Target:** `http://4.239.160.144:8080/product-service`
- **Modo:** Spider + Active Scan
- **Policy:** Baseline (no invasivo)

**Vulnerabilidades Evaluadas:**
- SQL Injection
- XSS (Cross-Site Scripting)
- Security Headers (CSP, X-Frame-Options, HSTS)
- Exposed Actuator Endpoints
- Cookie Security (HttpOnly, Secure flags)

**IntegraciÃ³n CI/CD:**
```yaml
- name: OWASP ZAP Scan
  uses: zaproxy/action-baseline@v0.7.0
  with:
    target: 'http://4.239.160.144:8080'
    rules_file_name: '.zap/rules.tsv'
    fail_action: true
```

### 3.2 Recomendaciones de MitigaciÃ³n

| Vulnerabilidad | Severidad | MitigaciÃ³n |
|----------------|-----------|------------|
| Actuator sin autenticaciÃ³n | ðŸŸ¡ Media | Agregar Spring Security |
| CORS permisivo | ðŸŸ¡ Media | Configurar allowedOrigins especÃ­ficos |
| Headers faltantes | ðŸŸ¢ Baja | Agregar Security Headers Filter |

---

## ðŸ¤– 4. AutomatizaciÃ³n: CI/CD con GitHub Actions

### 4.1 Pipeline de Quality Gates

**Workflow:** `.github/workflows/quality-gate.yml`

**Etapas:**
1. **Build & Test:** CompilaciÃ³n Maven + JUnit
2. **Coverage Check:** JaCoCo valida cobertura mÃ­nima (20%)
3. **SAST:** SonarCloud analiza cÃ³digo estÃ¡tico
4. **DAST:** OWASP ZAP escanea endpoints desplegados
5. **Performance:** Locust ejecuta smoke test

**Quality Gates:**
```yaml
- name: Maven Verify
  run: mvn -B clean verify
  
- name: JaCoCo Coverage Check
  run: mvn -B jacoco:check
  # Falla si cobertura < 20%
  
- name: SonarCloud Scan
  run: mvn -B sonar:sonar
  env:
    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
```

### 4.2 ConfiguraciÃ³n de JaCoCo

**Umbral MÃ­nimo:** 20% de cobertura (LINE + INSTRUCTION)

**Exclusiones:**
- MÃ³dulos de infraestructura (Eureka, Config Server, Gateway)
- Clases sin lÃ³gica de negocio (`*Application.class`)

**ConfiguraciÃ³n (`pom.xml`):**
```xml
<execution>
    <id>jacoco-check</id>
    <phase>verify</phase>
    <goals>
        <goal>check</goal>
    </goals>
    <configuration>
        <rules>
            <rule>
                <element>BUNDLE</element>
                <limits>
                    <limit>
                        <counter>LINE</counter>
                        <value>COVEREDRATIO</value>
                        <minimum>0.20</minimum>
                    </limit>
                </limits>
            </rule>
        </rules>
    </configuration>
</execution>
```

---

## ðŸ“Š 5. MÃ©tricas y Reportes

### 5.1 MÃ©tricas de Calidad

| MÃ©trica | Valor Actual | Objetivo |
|---------|--------------|----------|
| Cobertura de CÃ³digo | 26-29% | 30% |
| Tests Unitarios | 11/11 âœ… | 100% pass |
| Tests IntegraciÃ³n | 8/8 âœ… | 100% pass |
| Tests E2E | 3/3 âœ… | 100% pass |
| Latencia P95 (Locust) | TBD | <500ms |
| Disponibilidad | 99%+ | 99.9% |

### 5.2 Reportes Generados

**JaCoCo HTML Report:**
```
target/site/jacoco/index.html
```

**Locust Performance Report:**
```
performance_report.html
```

**OWASP ZAP Report:**
```
zap-report.html
```

---

## ðŸŽ¯ 6. Conclusiones y Mejores PrÃ¡cticas

### 6.1 Lecciones Aprendidas

âœ… **Shift-Left Testing:** Detectar bugs en etapas tempranas (unit tests) es 10x mÃ¡s barato que en producciÃ³n  
âœ… **FinOps:** Optimizar costos de nube mediante Smoke Tests en lugar de Stress Tests masivos  
âœ… **Pragmatismo:** Aceptar limitaciones de infraestructura (FK constraints en H2) y validar lo esencial  
âœ… **AutomatizaciÃ³n:** Quality Gates en CI/CD previenen regresiones  

### 6.2 PrÃ³ximos Pasos

ðŸ”œ **Testcontainers:** Integrar MySQL real con Docker en tests de integraciÃ³n  
ðŸ”œ **Contract Testing:** Implementar Pact para validar contratos entre microservicios  
ðŸ”œ **Chaos Engineering:** Introducir fallos controlados (Circuit Breaker, Timeout)  
ðŸ”œ **APM:** Integrar New Relic/Dynatrace para monitoreo en producciÃ³n  

---

## ðŸ“š Referencias

- [Testing Pyramid - Martin Fowler](https://martinfowler.com/articles/practical-test-pyramid.html)
- [FinOps Foundation](https://www.finops.org/)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)
- [Locust Documentation](https://docs.locust.io/)
- [JaCoCo Maven Plugin](https://www.jacoco.org/jacoco/trunk/doc/maven.html)

---

**Elaborado por:** Equipo de QA y DevOps  
**Fecha:** 27 de Noviembre de 2025  
**VersiÃ³n:** 1.0

### Pipelines de Calidad (Quality Gates)
Se ha configurado un workflow de GitHub Actions (`quality-gate.yml`) que actÃºa como barrera de calidad, impidiendo el paso de cÃ³digo que no compile o falle en las pruebas unitarias.